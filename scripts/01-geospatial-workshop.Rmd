---
title: "Geospatial Analysis in R"
author: "Kim Kreiss"
output:
  beamer_presentation:
    slide_level: 2
    toc: true
---

# Introduction

## Why R?

-   Reproducibility and Transparency

-   Flexibility and Customization

-   Integration with Statistical Analysis

-   Geospatial Visualization

## Today

-   We will analyze crime data in Chicago together:

    -   Combine point data and boundary file
    -   Generate informative visualizations
    -   Apply statistical techniques to identify hot and cold spots

-   This is an interactive workshop, where you are provided with code and data to run locally:

    -   `01-geospatial-workshop.Rmd`
    -   `2016-2020-chicago-crime.csv`
    -   `Boundaries - Neighborhoods.geojson`
    -   `Boundaries - Census Tracts - 2010.geojson`

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval=T, warning=F, message=F)
```

# Brief re-intro to spatial data and mapping

## Spatial Data

-   Most commonly point data, boundary data, grid or raster data

    -   point data: longitude and latitude of a unit of interest
    -   boundary data: polygon/shape data delineating a geographical area
    -   grid or raster data: usually squares/rectangles over the Earth's surface with specific attributes

-   Uses Coordinate Reference System (CRS)

## Mapping

-   Common application is to show point data within a region or geographic boundaries of interest, ie, are homicides in Chicago concentrated in certain neighborhoods?
-   Let's map crime in Chicago neighborhoods and census tracts

```{r}
# Load required libraries
library(sf)
library(spdep)
library(spatstat)
library(tidyverse)
library(colorspace)
```

## Read in the data

\scriptsize

```{r}

crime_data <- read.csv("../data/2016-2020-chicago-crime.csv")

neighborhoods <- st_read("../data/Boundaries - Neighborhoods.geojson",quiet=T)

census_tracts <- st_read("../data/Boundaries - Census Tracts - 2010.geojson", quiet=T)

homicide <- crime_data %>% 
  filter(Primary.Type=="HOMICIDE")

```

## Code: Homicides in Chicago Neighborhoods

\scriptsize

```{r, }
neighborhoods_map <- neighborhoods %>%
  ggplot() + 
  geom_point(data = homicide, aes(x=Longitude, y=Latitude), shape=1, color="red",size=.005)+
  geom_sf(aes(geometry=geometry), fill="transparent", linewidth=.25) + 
  theme(axis.text.x = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks = element_blank(),
        rect = element_blank(), 
        legend.position = "bottom") + 
  labs(x="", y="")#, title = "Homicides in Chicago (2016-2019)", 
      # subtitle = "By Neighborhood")
```

## Output: Homicides in Chicago (2016-2019) by Neighborhood

```{r, eval=T, echo=F}
neighborhoods_map
```

## Code: Homicides in Chicago Census Tracts

\scriptsize

```{r}
tracts_map <- census_tracts %>%
  ggplot() + 
  geom_point(data = homicide, aes(x=Longitude, y=Latitude), shape=1, color="red",size=.005)+
  geom_sf(aes(geometry=geometry), fill="transparent", linewidth=.25) + 
  theme(axis.text.x = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks = element_blank(),
        rect = element_blank(), 
        legend.position = "bottom") + 
  labs(x="", y="") #, title = "Homicides in Chicago (2016-2019)", 
      # subtitle = "By Neighborhood")
```

## Output: Homicides in Chicago (2016-2019) by Census Tract

```{r, eval=T, echo=F}
tracts_map
```

## Comparison

```{r eval=T, echo=F, fig.width=3.8}
neighborhoods_map
tracts_map
```

## Let's make neighborhood and census tract heat maps now

```{r}
point_sf <- st_as_sf(homicide, coords = c("Longitude", "Latitude"), crs = 4326) # coordinate reference systems  

#crs=4326 WGS 1984 latitudes and longitudes (EPSG 4326), this is the most popular projection

neighborhoods$homicides <- lengths(st_intersects(neighborhoods, point_sf))
census_tracts$homicides <- lengths(st_intersects(census_tracts, point_sf))
```

## Neighborhood Heat Map

```{r}
neighborhood_heat_map <- neighborhoods %>%
  ggplot() + 
  geom_sf(aes(geometry=geometry, fill=homicides), linewidth=.25) + 
  theme(axis.text.x = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks = element_blank(),
        rect = element_blank(), 
        legend.position = "none") + 
  labs(x="", y="") + 
  scale_fill_continuous_divergingx(palette = 'RdBu', mid = median(neighborhoods$homicides), rev=T,name = "")

```

## Census Tract Heat Map

```{r}
tract_heat_map <- census_tracts %>%
  ggplot() + 
  geom_sf(aes(geometry=geometry, fill=homicides), linewidth=.25) + 
  theme(axis.text.x = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks = element_blank(),
        rect = element_blank(), 
        legend.position = "none") + 
  labs(x="", y="") + 
  scale_fill_continuous_divergingx(palette = 'RdBu', mid = median(census_tracts$homicides), rev=T,name = "")

```

## Heat Map Comparison

```{r eval=T, echo=F, fig.width=3.8}
neighborhood_heat_map
tract_heat_map
```

## Point Pattern Analysis

-   Heat maps and other visuals can be informative but often want to do more rigorous analysis of spatial point patterns

-   We are interested in understanding the spatial distribution of homicides in Chicago:

    -   Are homicide events distributed randomly, clustered, or dispersed?
    -   What is the overall density or intensity of events across the study area? What are the underlying processes driving the spatial distribution of points?
    -   Are there statistically significant clusters of events in the study area?
    -   Where are the areas with significantly higher or lower homicide event densities compared to the surrounding areas?

-   We can apply these questions and framework to analyzing any point pattern data within a region

# Kernel Density Estimation

## Spatial Point Patterns

-   Countable sets of points that arise as realizations of stochastic point processes taking values in $A\subset R^2$
-   A spatial point pattern can be denoted as $\{x_1, x_2,...,x_{N(A)}\}$, where $N(A)$ is the number of points in $A$ where $N(A)$ is a random variable.
-   Thus, different realizations of the spatial point process may result in both different numbers and locations of points (Spatial Statistics, Ch. 17)
-   Refer to the points as events
-   We will use `spatstat` package to analyze point patterns

## spatstat 

+ We will use `density.ppp()` function from spatstat for kernel density estimation 
+ Technical notes on `spatstat`: 
    + spatial point patterns are represented as objects of class `ppp` (planar point pattern)
    + the `as.ppp()` function converts a `sf` object to a `ppp` object and takes as inputs point coordinates and an observation window (either a bounding box or a polygon)

```{r}
library(spatstat)

borders = st_transform(neighborhoods$geometry, crs=6454)
#Point patterns must be projected (rather than being lat/long), so the Illinois East State Plane Cordinate System in meters (EPSG 6454) is used. If you are analyzing a different area, you should use a planar coordinate system appropriate to your area.

ppp.homicide = as.ppp(st_transform(point_sf$geometry, crs=6454))

density.homicide = density.ppp(ppp.homicide, w=as.owin(borders), sigma=500)
density.homicide = density.ppp(ppp.homicide, sigma=500)


plot(density.homicide, col=colorRampPalette(c("navy", "gray", "red")), main = "Density of Homicides in Chicago (2016-2019)")
plot(borders, col=NA, border="gray", add=T)

## incorpoarting plotly/ double check the ggplot2
```

# Global and Local Moran's I

# Getis-Ord / G\*

# Wrap-up

```{r}

# talk about different weight matrices options 
# contiguous, inverse etc., why use one over the other
# talk about how these are used, why people use in dependent, independent, etc. dependence on your question; kernel function for neighborhood weight matrix
library(spdep)

neighbors = poly2nb(as_Spatial(neighborhoods), queen=T)

weights = nb2listw(neighbors, style="W", zero.policy=T)

plot(st_geometry(neighborhoods), border="gray")

plot(neighbors, coords=st_coordinates(st_centroid(neighborhoods)), add=T)
```

```{r}
## also do global moran's I and talk about difference btwn local vs. global 

neighborhoods$rate = neighborhoods$homicides/sum(neighborhoods$homicides,na.rm = T)
local = localmoran(neighborhoods$rate, weights)

neighborhoods$Morans.2020 = local[,"Z.Ii"]

breaks=c(-10, -1, 1, 10)

plot(neighborhoods["Morans.2020"], breaks=breaks,
         pal=colorRampPalette(c("navy", "gray", "red")))
```

```{r}
neighborhoods$Getis.Ord.2020 = localG(neighborhoods$rate, weights)

plot(neighborhoods["Getis.Ord.2020"], 
	breaks=c(-10, -1.645, -1.282, 1.282, 1.645, 10),
	pal=colorRampPalette(c("navy", "#f0f0f0", "red")))
```

## Next steps:

-   descriptions/slides for each type of analysis
-   consider using different geographical boundaries, ie census tracts, highlight modifiable area unit problem + parameters for different methods
-   resources on spatial regression, future directions, etc.
-   bigger data/computation: plug for Eric's workshop!!!

package dependencies

some other demographic/neighborhood characteristics that are associated with higher crimes, etc.

add in population data for the neighborhoods and census tracts

if you have other high frequency data, ie cell phone data or all crime data as benchmark for computation time spatial heterogeneity ??

source: <https://michaelminn.net/tutorials/r-crime/>

<!-- ```{r} -->

<!-- # Load example point data -->

<!-- data <- read_csv("~/Downloads/crime.csv") %>%  -->

<!--   as.data.frame() %>% -->

<!--   filter(geo_lat!=0 & geo_lon< -5 & geo_lon > -112) -->

<!-- plot(data$geo_lon, data$geo_lat, col = "blue",  -->

<!--      xlab = "Longitude", ylab = "Latitude", main = "Point Data", size=.005, cex = .5) -->

<!-- ``` -->

<!-- ```{r} -->

<!-- # Create crime point data -->

<!-- crime_data <- data.frame( -->

<!--   ID = 1:100, -->

<!--   Longitude = runif(100, -105.3, -104.7), # Generate random longitudes within a range -->

<!--   Latitude = runif(100, 39.6, 40.2)       # Generate random latitudes within a range -->

<!-- ) -->

<!-- coordinates(crime_data) <- c("Longitude", "Latitude")  # Convert to SpatialPointsDataFrame -->

<!-- # Create administrative polygon data (e.g., neighborhoods) -->

<!-- # For demonstration purposes, let's create a grid of polygons covering the city -->

<!-- # You would typically load administrative boundary shapefiles for real-world data -->

<!-- grid <- GridTopology(c(-105.3, 39.6), c(0.1, 0.1), c(10, 10))  # Define grid covering the city -->

<!-- polygons <- as.SpatialPolygons.GridTopology(grid)  # Convert grid to SpatialPolygons -->

<!-- # Assign attributes to the polygons -->

<!-- # For demonstration purposes, let's assign random crime counts to each polygon -->

<!-- polygons_data <- data.frame( -->

<!--   ID = 1:100, -->

<!--   Crime_Count = sample(1:20, 100, replace = TRUE)  # Random crime counts for each polygon -->

<!-- ) -->

<!-- row.names(polygons_data) <- sapply(slot(polygons, "polygons"), function(x) slot(x, "ID")) -->

<!-- # Combine the polygon data with the polygons -->

<!-- polygons <- SpatialPolygonsDataFrame(polygons, polygons_data) -->

<!-- # Plot the crime points and administrative polygons -->

<!-- plot(polygons, col = "lightblue", border = "black") -->

<!-- points(crime_data, col = "red", pch = 20) -->

<!-- # Create crime count variable in crime_data -->

<!-- crime_data$Crime_Count <- sample(1:20, nrow(crime_data), replace = TRUE) -->

<!-- ``` -->

<!-- ```{r}  -->

<!-- # Create a neighbor list based on polygon adjacency -->

<!-- W <- poly2nb(polygons) -->

<!-- W <- nb2listw(W, style = "B") -->

<!-- # Conduct Local Moran's I -->

<!-- local_moran <- localmoran(crime_data$Crime_Count, W) %>%  -->

<!--   as.data.frame() %>%  -->

<!--   mutate(ID = seq(1,100,1)) -->

<!-- # Print the results -->

<!-- print(local_moran) -->

<!-- # Conduct Getis-Ord Gi* statistics -->

<!-- getis_ord <- localG(crime_data$Crime_Count, W) %>%  -->

<!--   as.data.frame() %>%  -->

<!--   mutate(ID = seq(1,100,1)) -->

<!-- # Print the results -->

<!-- print(getis_ord) -->

<!-- ``` -->

<!-- ```{r} -->

<!-- # Plot the administrative polygons -->

<!-- plot(polygons, col = "lightblue", border = "black") -->

<!-- # Plot Local Moran's I results as a heatmap indicating hot and cold spots -->

<!-- plot(local_moran$Ii, col = colorRampPalette(c("blue", "white", "red"))(100), add = TRUE) -->

<!-- # Add legend for Local Moran's I heatmap -->

<!-- legend("topright", legend = "Local Moran's I", fill = colorRampPalette(c("blue", "white", "red"))(100), bty = "n") -->

<!-- ``` -->
